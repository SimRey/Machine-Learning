{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Introduction to Simple Linear Regression</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data\n",
    "\n",
    "This sample data is from ISLR. It displays sales (in thousands of units) for a particular product as a function of advertising budgets (in thousands of dollars) for TV, radio, and newspaper media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Lenovo/Desktop/Python/Machine Learning/Supervised Learning/Linear regression/Data Sets/Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relationship between *total* advertising spend and *sales*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_spend'] = df['TV'] + df['radio'] + df['newspaper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='total_spend',y='sales',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, we want to figure out how to create this line\n",
    "\n",
    "sns.regplot(x='total_spend',y='sales',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and start solving: $$y=mx+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply solve for m and b, remember, that as shown in the video, we are solving in a generalized form:\n",
    "\n",
    "$$ \\hat{y} = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "Capitalized to signal that we are dealing with a matrix of values, we have a known matrix of labels (sales numbers) Y and a known matrix of total_spend (X). We are going to solve for the *beta* coefficients, which as we expand to more than just a single feature, will be important to build an understanding of what features have the most predictive power. We use $ \\hat{y}$ to indicate that $\\hat{y}$ is a prediction or estimation, y would be a true label/known value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['total_spend']\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving it by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the general formula:\n",
    "$$ \\hat{y} = \\beta_0 + \\beta_1X$$\n",
    "\n",
    "The least squares line has two components: the slope $\\beta_1$, and y-intercept $\\beta_0$. We will solve for $\\beta_1$ first, and then solve for $\\beta_0$. The equations for $\\beta_1$ and $\\beta_0$ are:\n",
    "\n",
    "$$\\beta_1 = \\frac{n*(\\sum{Xy}) - (\\sum{X})(\\sum{y})}{n(\\sum{X}^2)-(\\sum{X})^2} = \\frac{\\sum{(X_i-\\bar{X})(y_i - \\bar{y})}}{(\\sum{(X_i-\\bar{X})^2}}$$\n",
    "\n",
    "$$\\beta_0 = \\frac{\\sum{y}-\\beta_1\\sum{X}}{n} = \\bar{y}-\\beta_1\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]\n",
    "\n",
    "b1 = (n*sum(X*y) - (sum(X)*sum(y)))/(n*sum(X*X) - (sum(X))**2)\n",
    "b0 = (sum(y) - b1*sum(X))/n\n",
    "\n",
    "b1, b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using built in packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### np.polyfit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns highest order coef first!\n",
    "betas = np.polyfit(X,y,1)  # As it can be seen, it is fitted to a straight line, polinomial of order one, however,\n",
    "# polynomials of higher degree could also be adjusted, changing the 1, by the required degree. \n",
    "\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Difference between the 2 models b1 {betas[0] - b1} and b0 {betas[1] - b0}\")\n",
    "\n",
    "# As we can see both models perform practically the same, giving the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Library scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import *\n",
    "beta1, beta0, r_value, p_value, std_error = linregress(X, y)\n",
    "print(f\"\"\"Slope: {beta1}\n",
    "Y-Intercept: {beta0}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing the lines \n",
    "plt.figure(figsize=(12,6))\n",
    "potential_spend = np.linspace(0,500,100)\n",
    "\n",
    "manual = b1*potential_spend + b0\n",
    "pol_nump = betas[0]*potential_spend + betas[1]\n",
    "scipy_pol = beta1*potential_spend + beta0\n",
    "\n",
    "sns.scatterplot(x='total_spend',y='sales',data=df)\n",
    "\n",
    "plt.plot(potential_spend,manual,color='red', linestyle=\"dashed\")\n",
    "plt.plot(potential_spend,pol_nump,color='green', linestyle=\"solid\")\n",
    "plt.plot(potential_spend,scipy_pol,color='orange', linestyle=\"dotted\")\n",
    "plt.title(\"Various regressions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impossible to see the difference, all tree methods give the same values. As it can be seen, there are many ways to perform a linear regression, these are just some examples, many other libraries enable to do the same or more complex tasks. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
